{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import Azure ML Python SDK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget"
   ]
  },
  {
   "source": [
    "# Connect to workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace.get(\n",
    "#     name=\"automl-compute\", subscription_id='d020e68d-d282-4cb4-bf4e-91772428dd56', resource_group='Telco_ML')\n",
    "\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"d020e68d-d282-4cb4-bf4e-91772428dd56\", force=True)\n",
    "\n",
    "ws = Workspace(subscription_id=\"d020e68d-d282-4cb4-bf4e-91772428dd56\",\n",
    "               resource_group=\"Telco_ML\",\n",
    "               workspace_name=\"automl-compute\",\n",
    "               auth=interactive_auth)\n",
    "'''\n",
    "According to MS docs, all users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. The creator of the compute instance has the compute instance dedicated to them, have root access, and can terminal in through Jupyter. Compute instance will have single-user login of creator user and all actions will use that userâ€™s identity for RBAC and attribution of experiment runs. SSH access is controlled through public/private key mechanism.\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python\n",
    "'''\n",
    "# auth = InteractiveLoginAuthentication(tenant_id ='d020e68d-d282-4cb4-bf4e-91772428dd56')\n",
    "# ws = Workspace.from_config(auth = auth)"
   ]
  },
  {
   "source": [
    "# Create an experiment instance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name=\"experiment-1-voting-ensembler\"\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "source": [
    "# Connect to the compute cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amlcompute_cluster_name=\"telco-ml-compute\"\n",
    "cts=ws.compute_targets\n",
    "compute_target=cts[amlcompute_cluster_name]"
   ]
  },
  {
   "source": [
    "# Get the most recent run info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_id='AutoML_a88df5be-cfd2-484b-abdc-400e6bb84460'\n",
    "training_run=AutoMLRun(experiment, run_id)\n",
    "training_run"
   ]
  },
  {
   "source": [
    "# Get details of the run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run.get_details()"
   ]
  },
  {
   "source": [
    "# Get the best fitted model info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run,fitted_model=training_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c anaconda azureml-train-automl-runtime==1.19.0  \n",
    "# conda install -c conda-forge azureml-train-automl-runtime==1.19.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=best_run.properties['model_name']\n",
    "model_name"
   ]
  },
  {
   "source": [
    "## Save the executive file into the repo "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_file_name='inference/score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)"
   ]
  },
  {
   "source": [
    "# Register the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "description =\"telecom customer churn best model\"\n",
    "model=training_run.register_model(model_name=model_name, description=description, tags=None)\n",
    "print(training_run.model_id)"
   ]
  },
  {
   "source": [
    "# Deploy the model and create a web service"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# Define what script to run, which environment to use\n",
    "inference_config=InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())\n",
    "\n",
    "# Define the deployment configuration for Azure Container Instance(ACI)\n",
    "aciconfig=AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, tags={'type':'automl-churnpredictor'}, description='Sample service for customer churn prediction')\n",
    "\n",
    "# Deploy the model as a Web Service\n",
    "aci_service_name=\"customer-churn-detection-ser\"\n",
    "print(aci_service_name)\n",
    "aci_service=Model.deploy(ws,aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "source": [
    "# Test the model\n",
    "## Get the test data and drop the churn column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data includes 39 rows of customer data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "test_df=pd.read_csv('NewData-Telco-Customer-Retention.csv')\n",
    "test_df_woc=test_df.drop('Churn',axis=1)\n",
    "\n",
    "test_df_woc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_woc is the dataset without 'Churn' column\n",
    "# We need to transform it into json format\n",
    "test_sample={'data':test_df_woc.to_dict(orient='records')}\n",
    "# Call the Web Service\n",
    "# response=aci_service.run(input_data=test_sample)\n",
    "# test_sample"
   ]
  },
  {
   "source": [
    "# Make an API call to the deployed model with sending the test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://5c7ee551-fae1-4672-8549-44dbc9eba189.westeurope.azurecontainer.io/score\"\n",
    "\n",
    "payload=test_sample\n",
    "headers = {\n",
    "  'operationId': 'RunMLService',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "#API call to model\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "# get the list part from response as a string\n",
    "listed_response=response.text[14:-2]\n",
    "#convert string to list \n",
    "pythonic_list=json.loads(listed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then result list to pandas dataframe\n",
    "predicted_all=pd.DataFrame(pythonic_list)\n",
    "predicted_all['Predicted']=pythonic_list"
   ]
  },
  {
   "source": [
    "## Display the response (as actual and predicted columns side by side )"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display side by side the truth and predicted response from API\n",
    "webservice_df=pd.DataFrame({'Actual': test_df['Churn'], 'Predicted':predicted_all['Predicted']})\n",
    "webservice_df"
   ]
  },
  {
   "source": [
    "## Analyze the accuracy level"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for index, row in webservice_df.iterrows():\n",
    "    if row['Actual']=='Yes' and row['Predicted']==True or row['Actual']=='No' and row['Predicted']==False:\n",
    "        print(row['Actual'], row['Predicted'], True)\n",
    "    else:\n",
    "        print(row['Actual'], row['Predicted'],'-----',index, '-----')\n",
    "        counter+=1"
   ]
  },
  {
   "source": [
    "# Illustrate the accuracy percentage using plots:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "value_SenCit = counter/ len(webservice_df) * 100 # 7.7\n",
    "\n",
    "# Pie chart:\n",
    "label_Truth = ['False Prediction', 'True Prediction']\n",
    "sizes = [value_SenCit, 100-value_SenCit]\n",
    "explode = (0, 0.1)  # only \"explode\" the 2nd slice\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=label_Truth, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title('Accuracy Rate', loc='center', pad = 100, fontdict={'fontsize':18})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_type(v):\n",
    "#     if isinstance(v, np.integer):\n",
    "#         v=int(v)\n",
    "#     elif isinstance(v, np.floating):\n",
    "#         v=float(v)\n",
    "    # elif isinstance(v, np.ndarray):\n",
    "    #     v=v.tolist()"
   ]
  },
  {
   "source": [
    "# Sample implementation of making a call with user-filled form submission and getting the prediction response from the API. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data includes 39 rows of customer data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "test_df=pd.read_csv('NewData-Telco-Customer-Retention.csv')\n",
    "test_df_woc=test_df.drop('Churn',axis=1)\n",
    "p1='is likely to churn. You had better take some action!'\n",
    "p2='is happy and loyal. No need to take extra precautions.'\n",
    "\n",
    "# test_df_woc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(k,v):\n",
    "    print(f'Selected value is {v}')\n",
    "    # check_type(v)\n",
    "    if isinstance(v, np.integer):\n",
    "        v=int(v)\n",
    "    elif isinstance(v, np.floating):\n",
    "        v=float(v)\n",
    "    new_cust_data[k]=v\n",
    "\n",
    "new_cust_data={}\n",
    "for k in test_df.columns[:-1]:\n",
    "    if k=='customerID':\n",
    "        k=widgets.interact(get_val, k=k, v='')\n",
    "    else:\n",
    "        widgets.interact(get_val, k=k,v=sorted(test_df[k].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust_data"
   ]
  },
  {
   "source": [
    "## Make the call, get the response"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://5c7ee551-fae1-4672-8549-44dbc9eba189.westeurope.azurecontainer.io/score\"\n",
    "\n",
    "payload={\"data\":[new_cust_data]}\n",
    "headers = {\n",
    "  'operationId': 'RunMLService',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "#API call to model\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "source": [
    "# Show the response"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black', 'height':'100px'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with out:\n",
    "    parsed_json = json.loads(response.text)[12:-2]\n",
    "    if parsed_json==\"true\":\n",
    "        print(f\"{new_cust_data['customerID']} {p1}\")\n",
    "    elif parsed_json==\"false\":\n",
    "        print(f\"{new_cust_data['customerID']} {p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils widgets\n",
    "from ipywidgets import Button, Layout, jslink, IntText, IntSlider, TwoByTwoLayout\n",
    "from data_dict import findings\n",
    "def create_expanded_button(description, button_style):\n",
    "    return Button(description=description, button_style=button_style, layout=Layout(height='auto', width='auto'))\n",
    "\n",
    "top_left_button = create_expanded_button(findings['a'], 'danger')\n",
    "top_right_button = create_expanded_button(findings['b'], 'success')\n",
    "bottom_left_button = create_expanded_button(findings['c'], 'info')\n",
    "bottom_right_button = create_expanded_button(findings['d'], 'warning')"
   ]
  },
  {
   "source": [
    "# Our Findings and Considerations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoByTwoLayout(top_left=top_left_button,\n",
    "               top_right=top_right_button,\n",
    "               bottom_left=bottom_left_button,\n",
    "               bottom_right=bottom_right_button,\n",
    "               height=\"200px\")"
   ]
  },
  {
   "source": [
    "# One-pager"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='one_pager.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}